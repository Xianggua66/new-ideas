{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "模型构造.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zVoK5JUbDT9"
      },
      "source": [
        "首先，回忆一下多层感知机"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6vFl02gasde"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "590YUjsMbN5p",
        "outputId": "86bfc3fb-71b7-46d1-dcce-1ca5c603deb3"
      },
      "source": [
        "net=nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
        "X=torch.rand(2,20)\n",
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0551, -0.2536,  0.0096, -0.0515, -0.0462,  0.1455, -0.1643, -0.0903,\n",
              "          0.3246, -0.0154],\n",
              "        [ 0.1044, -0.0854,  0.1892, -0.0471, -0.0281,  0.1852, -0.0816, -0.1357,\n",
              "          0.2563,  0.0503]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqH3tTIfboOg"
      },
      "source": [
        "自定义块"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa7MA3LAbbiz"
      },
      "source": [
        "#和上面的模型一样\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden=nn.Linear(20,256)\n",
        "    self.out=nn.Linear(256,10)\n",
        "\n",
        "  def forward(self,X):\n",
        "    return self.out(F.relu(self.hidden(X)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6xmcEpscoOU"
      },
      "source": [
        "实例化多层感知机的层，然后在每次调用正向传播函数时调用这些层"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OV7N43DcuxI",
        "outputId": "2845d824-4622-4397-cbcb-2c683c3e3e69"
      },
      "source": [
        "net=MLP()\n",
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0069,  0.3055,  0.1357,  0.0674, -0.2480, -0.1679,  0.1056,  0.0578,\n",
              "          0.1124, -0.0241],\n",
              "        [-0.0706,  0.1582,  0.1425, -0.1122, -0.1492, -0.0686,  0.0096,  0.0643,\n",
              "         -0.1240,  0.0565]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7ZYpstVdDQB"
      },
      "source": [
        "顺序块"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY_QES3ycyEl",
        "outputId": "fbaf5b35-971b-4d67-878a-8a0364c91da8"
      },
      "source": [
        "class MYSequential(nn.Module):\n",
        "  def __init__(self,*args):\n",
        "    super().__init__()\n",
        "    for block in args:\n",
        "      self._modules[block]=block\n",
        "  \n",
        "  def forward(self,X):\n",
        "    for block in self._modules.values():\n",
        "      X=block(X)\n",
        "    return X\n",
        "\n",
        "net=MYSequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
        "net(X)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3686,  0.1643,  0.0918,  0.0381, -0.1996, -0.0994, -0.3390, -0.0632,\n",
              "          0.0231, -0.0912],\n",
              "        [-0.1383,  0.0167, -0.0256, -0.0704, -0.2475, -0.1524, -0.2265, -0.0599,\n",
              "          0.0457, -0.0889]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su4GbUp0eqsZ"
      },
      "source": [
        "在正向传播中执行代码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB_ENPXdetDN",
        "outputId": "c2f0b768-7881-43db-ba36-f48fe63de9e6"
      },
      "source": [
        "class FixedHiddenMLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.rand_weight=torch.rand((20,20),requires_grad=False)\n",
        "    self.linear=nn.Linear(20,20)\n",
        "  \n",
        "  def forward(self,X):\n",
        "    X=self.linear(X)\n",
        "    X=F.relu(torch.mm(X,self.rand_weight)+1)#矩阵乘法\n",
        "    X=self.linear(X)\n",
        "    while X.abs().sum()>1:\n",
        "      X/=2\n",
        "    return X.sum()\n",
        "\n",
        "net=FixedHiddenMLP()\n",
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0671, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9TF5NgngNda"
      },
      "source": [
        "混合搭配各种组合块的方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSoZWLyTgQ23",
        "outputId": "133836a9-db25-488a-db08-096f417fe0f3"
      },
      "source": [
        "class NestMLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net=nn.Sequential(nn.Linear(20,64),nn.ReLU(),nn.Linear(64,32),nn.ReLU())\n",
        "    self.linear=nn.Linear(32,16)\n",
        "  \n",
        "  def forward(self,X):\n",
        "    return self.linear(self.net(X))\n",
        "  \n",
        "chimera=nn.Sequential(NestMLP(),nn.Linear(16,20),FixedHiddenMLP())\n",
        "chimera(X)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0180, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}